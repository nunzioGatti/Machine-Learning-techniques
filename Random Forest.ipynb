{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Link https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is a type of supervised machine learning algorithm based on ensemble learning. Ensemble learning is a type of learning where you join different types of algorithms or same algorithm multiple times to form a more powerful prediction model. The random forest algorithm combines multiple algorithm of the same type i.e. multiple decision trees, resulting in a forest of trees, hence the name \"Random Forest\". The random forest algorithm can be used for both regression and classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How the Random Forest Algorithm Works\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the basic steps involved in performing the random forest algorithm\n",
    "\n",
    "-Pick N random records from the dataset.\n",
    "    \n",
    "-Build a decision tree based on these N records.\n",
    "    \n",
    "-Choose the number of trees you want in your algorithm and repeat steps 1 and 2.\n",
    "    \n",
    "-In case of a regression problem, for a new record, each tree in the forest predicts a value for Y (output). The final value  can be calculated by taking the average of all the values predicted by all the trees in forest. \n",
    "    \n",
    "-In case of a classification problem, each tree in the forest predicts the category to which the new record belongs. Finally,  the new record is assigned to the category that wins the majority vote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantages of using Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-The random forest algorithm is not biased, since, there are multiple trees and each tree is trained on a subset of data. Basically, the random forest algorithm relies on the power of \"the crowd\"; therefore the overall biasedness of the algorithm is reduced.\n",
    "\n",
    "-This algorithm is very stable. Even if a new data point is introduced in the dataset the overall algorithm is not affected much since new data may impact one tree, but it is very hard for it to impact all the trees.\n",
    "\n",
    "-The random forest algorithm works well when you have both categorical and numerical features.\n",
    "\n",
    "-The random forest algorithm also works well when data has missing values or it has not been scaled well (although we have performed feature scaling in this article just for the purpose of demonstration)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disadvantages of using Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-A major disadvantage of random forests lies in their complexity. \n",
    "They required much more computational resources, owing to the large number of decision trees joined together.\n",
    "\n",
    "-Due to their complexity, they require much more time to train than other comparable algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Using Random Forest for Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Definition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is to predict the gas consumption (in millions of gallons) in 48 of the US states based on petrol tax (in cents), per capita income (dollars), paved highways (in miles) and the proportion of population with the driving license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./petrol_consumption.csv\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4399</td>\n",
       "      <td>431</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "0         9.0            3571            1976                         0.525   \n",
       "1         9.0            4092            1250                         0.572   \n",
       "2         9.0            3865            1586                         0.580   \n",
       "3         7.5            4870            2351                         0.529   \n",
       "4         8.0            4399             431                         0.544   \n",
       "\n",
       "   Petrol_Consumption  \n",
       "0                 541  \n",
       "1                 524  \n",
       "2                 561  \n",
       "3                 414  \n",
       "4                 410  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create attributes \n",
    "\n",
    "X = dataset.iloc[:,:4].values\n",
    "Y = dataset.iloc[:,4:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StandardScaler transforms your data in a distribution that will have a mean value 0 \n",
    "#and standard deviation of 1\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gatto\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# n_estimators = number of trees \n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)  \n",
    "regressor.fit(X_train, Y_train)  \n",
    "y_pred = regressor.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 68.44500000000002\n",
      "Mean Squared Error: 6656.516250000002\n",
      "Root Mean Squared Error: 81.58747606097398\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576.7708333333334"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Petrol_Consumption'].mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "With 20 trees, the root mean squared error is 64.93 which is greater than 10 percent of the average petrol consumption i.e. 576.77. This may indicate, among other things, that we have not used enough estimators (trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 65.155\n",
      "Mean Squared Error: 6368.158874999999\n",
      "Root Mean Squared Error: 79.80074482735107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gatto\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# n_estimators = number of trees \n",
    "regressor = RandomForestRegressor(n_estimators=40, random_state=0)  \n",
    "regressor.fit(X_train, Y_train)  \n",
    "y_pred = regressor.predict(X_test)  \n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Using Random Forest for Classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Problem Definition\n",
    "\n",
    "The task here is to predict whether a bank currency note is authentic or not based on four attributes \n",
    "-variance of the image  : variance is normally used to find how each pixel varies from the neighbouring pixel (or centre pixel)                            and is used in classify into different regions\n",
    "-skewness               : asimmetria\n",
    "-entropy                : In the case of an image, the entropy represents the distibution af the pixel values. For example, in                              an 8-bit pixel there are 256 possible states. If all such states are equally occupied, as they are in                            the case of an image which has been perfectly histogram equalized, the spread of states is a maximum,                            as is the entropy of the image. On the other hand, if the image has been thresholded, so that only                              two states are occupied, the entropy is low. If all of the pixels have the same value, the entropy of                            the image is zero.\n",
    "-curtosis of the image  : kurtosis was a measure of the flatness of the distribution. The higher is the Kurtosis the higher the                           predominance of certain pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = pd.read_csv(\"./bill_authentication.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variance  Skewness  Curtosis  Entropy  Class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:4].values\n",
    "Y = dataset.iloc[:,4:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = dataset.iloc[:,4:].values\n",
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gatto\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)  \n",
    "regressor.fit(X_train, Y_train)  \n",
    "y_pred = regressor.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1 if x > 0.5 else 0 for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[155   2]\n",
      " [  0 118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       157\n",
      "           1       0.98      1.00      0.99       118\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       275\n",
      "   macro avg       0.99      0.99      0.99       275\n",
      "weighted avg       0.99      0.99      0.99       275\n",
      "\n",
      "0.9927272727272727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(Y_test,y_pred))  \n",
    "print(classification_report(Y_test,y_pred))  \n",
    "print(accuracy_score(Y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
